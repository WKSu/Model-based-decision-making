{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenRivers MORO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "# RELINK these\n",
    "In the previous two files, we performed open exploration of the base case (do nothing) with 1000 scenarios ([here](1.%20Open%20exploration%20base%20case.ipynb)) and a sample run with 400 scenarios and 75 policies ([here]()). The first step gave us an impression of what the system might look like if we do nothing. With the second, we were able to learn a lot more about the modelled world. Most importantly, we wanted to know what the total output space might look like, and if any policies (set of decisions) would lead to a worse outcome than the base case.\n",
    "\n",
    "With this information, we can begin doing Multi-objective Robust Optimization (MORO) with the model to find a set of non-dominated (i.e. best) policies across a whole range of scenarios.\n",
    "\n",
    "[WORDS](#s1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"s1\">1.1 Methodology</a>\n",
    "A methodology summary follows below; more detailed discussion of each step lives near it. Our MORO approach is based on Kwakkel, J. H., Haasnoot, M., & Walker, W. E. (2015). Developing dynamic adaptive policy pathways: a computer-assisted approach for developing adaptive strategies for a deeply uncertain world. Climatic Change, 132(3), 373–386. https://doi.org/10.1007/s10584-014-1210-4.\n",
    "\n",
    "\n",
    "\n",
    "1. Finally, run [MORO](#section_id). We use the $\\epsilon$-NSGA-II algorithm here.\n",
    "\n",
    "The term \"robustness\" is quite often defined differently. We use it as a measure of _how well a policy performs over different scenarios_.\n",
    "\n",
    "As a brief overview of MORO, its steps are mainly:\n",
    "1. Define a list of outcomes $o$ and what you want it to be optimized for (e.g. min)\n",
    "1. Sample a set of $n$ scenarios\n",
    "1. Create an $m$ sized population of test policies\n",
    "1. Test each of those policies again the scenarios ($n \\times m$ results)\n",
    "1. Evaluate the performance of each policy for each outcome over those scenarios on aggregate to determine its *robustness* over scenarios ($o \\times m$ results)\n",
    "1. Take the best performing policies (e.g. best 10%), mutate them into $m$ policies, and test them again against the $n$ scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2. Set up MORO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Required Packages and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter, Constraint)\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario, SequentialEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments, optimize\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging, utilities\n",
    "\n",
    "from visualization_functions import *\n",
    "\n",
    "# Set a logging style so we can peer into the process\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Robustness Functions\n",
    "\n",
    "For each policy, EMAworkbench extracts $o$ outcomes in an $[1 \\times o]$ array. However, to compare the policies against one another, we must define a robustness score for this entire set of outcomes.\n",
    "\n",
    "Additionally, in the dike model, we get outcomes for multiple points in time and space (e.g. investment costs of Room for the River projects can be at any location and any of the decision times). This actually leaves us with an $[x \\times o]$ array, where $x$ is the number of relevant variables for the overall outcome we are interested in. Therefore, we need to first sum that initial array into an $[1 \\times o]$ array. This is done in the `sumover_robustness()` function below.\n",
    "\n",
    "This step is quite important and potentially controversial: we are aggregating a metric in such a manner that individual performance is not necesarily reflected. We become impartial to location and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumover_robustness(*data):\n",
    "    '''\n",
    "    Aggregates multiple outcomes (across time and space) into one robustness score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : multiple n-length (but same) arrays and sums up element-wise into a [1,n] array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score: A score from the robustness function for the [1,n] array.\n",
    "    '''\n",
    "    score = robustness(sum(data))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, the robustness score is arbitrary. Here, we define it in `robustness()` as the mean of the outcome across the scenarios multiplied by the interquartile range (IQR) of the same. We chose this approach because we want to minimize both the mean and the amount of variation in the outcome space. Little variation means the policy is quite robust, and a low mean lets us achieve a result closer to our objective (e.g. low required investment cost).\n",
    "\n",
    "If someone wanted to maximize an outcome instead, then this function is not suitable. We add 0.5% of the mean to the IQR so that it does not dominate the robustness score. For instance, if the IQR is zero and the mean is not, the score will not be zero. If the mean is zero, the IQR will also already be zero (our model produces no negative values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness(data):\n",
    "    '''\n",
    "    Returns a robustness score for values in a [1,n] array, which you want to minimize.\n",
    "    \n",
    "    We want a function that returns 0 for the outcome to be in the range that we want and higher otherwise.\n",
    "    \n",
    "    This function multiplies the mean with the sum of the interquartile range and 0.5% of the mean.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : a [1,n] array from sumover_robustness()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    score : score for the [1,n] array\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Normalize\n",
    "    mean = np.mean(data)\n",
    "    iqr = sp.stats.iqr(data) + mean * 0.005 # Add a small number so the mean is still considered in the score rather than 0\n",
    "    score = mean * iqr\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 2.3 Determine MORO Convergence Metrics\n",
    "\n",
    "In any optimization, it is important to look understand if the algorithm has converged or not. There's no easy way to explain this, but perhaps two of [Zeno's paradoxes](https://en.wikipedia.org/wiki/Zeno%27s_paradoxes#Dichotomy_paradox) provides the best illustration. These algorithms are iterative and move closer and closer to their 'best' or 'true' value. We want to know when it is close enough for our satisfaction.\n",
    "\n",
    "![Zeno's Dichotomy Paradox by Martin Grandjean](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Zeno_Dichotomy_Paradox.png/800px-Zeno_Dichotomy_Paradox.png)\n",
    "\n",
    "Picture: Grandjean, Martin (2014) [Henri Bergson et les paradoxes de Zénon : Achille battu par la tortue ?](http://www.martingrandjean.ch/bergson-paradoxes-zenon-achille-tortue/). Accessed from [WikiMedia Commons](https://commons.wikimedia.org/wiki/File:Zeno_Dichotomy_Paradox.png).\n",
    "\n",
    "The EMAworkbench comes with two metrics: a hypervolume indicator and $\\epsilon$-convergence (epsilon). We will not go into further detail about them, but you can read about them [here (Reed et. al (2013)](https://doi.org/10.1016/j.advwatres.2012.01.005) and [here (Kasprzyk et. al (2012))](https://doi.org/10.1016/j.envsoft.2011.04.003), respectively (the former talks about $\\epsilon$ as well and is a better introduction). There is also a fantastic video about hypervolume indicators [here](https://www.youtube.com/watch?v=cR4r1aNPBkQ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Hypervolume Indicator Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypervolume indicator algorithm requires that we provide it with the expected range of each outcome. To understand the possibilities for these outcomes, we need to load our results from open exploration (random policies under random scenarios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from /Users/jrwang/Documents/Coding/Model-based-decision-making/Outcomes/400Scenarios75Policies.csv\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench.util.utilities import (save_results, load_results)\n",
    "\n",
    "results = load_results('Outcomes/400Scenarios75Policies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "outcomes = pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to aggregate each outcome we are interested in by time and space (the problems of doing this are already discussed in 2.2). Then, we can find the robustness score for every policy under every outcome. Finally, we will want to extract the minimum and the maximum values for each outcome's robustness score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_outcomes(outcomes,\"Expected Annual Damage\")\n",
    "aggregate_outcomes(outcomes,\"Dike Investment Costs\")\n",
    "aggregate_outcomes(outcomes,\"Expected Number of Deaths\")\n",
    "aggregate_outcomes(outcomes,\"RfR Total Costs\")\n",
    "aggregate_outcomes(outcomes,\"Expected Evacuation Costs\")\n",
    "\n",
    "everything = pd.DataFrame(experiments[\"policy\"]).join(outcomes)\n",
    "robust_values = everything.groupby(by = [\"policy\"]).apply(robustness).iloc[:, -5:]\n",
    "\n",
    "hyp_ranges_min = robust_values.apply(np.min)\n",
    "hyp_ranges_max = robust_values.apply(np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 $\\epsilon$-convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we follow Kasprzyk et al. in looking at the maximum variance of the dominating values (i.e. those near a Pareto front), which should yield $\\epsilon$ values that will speed up the algorithm. For this, we can ran a small MORO instance. Kaspryzk et al. used Monte Carlo sampling across their open exploration results, which is much faster than our approach. However, we're not quite sure if they picked the ones near their Pareto front though. In that sense, our values should be more useful. Unfortunately, this means we will have to set up and run MORO briefly. For now, we will choose to use a very small grid size – `0.05` for all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "from model.dike_model_function import DikeNetwork\n",
    "from model.problem_formulation import get_model_for_problem_formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again pick problem formulation `5` because it provides the most resolution of outcomes. Though we are aggregating them to apply the robustness score, we still want to see their raw output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dike_model, planning_steps = get_model_for_problem_formulation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define, in EMAworkbench terms, all the parameters we want to optimize for and the constraints we want to add to the optimization algorithm.\n",
    "\n",
    "Each of these $x$ variable names are aggregated in the $o$ outcomes. Explicitly, the outcome _investment costs in Room for the River projects_ can be made at all three decision steps (0, 1, and 2; $\\therefore o = 3$). We store these in `var_list_rfr` and then define the outcome later as a `ScalarOutcome` with the name 'RfR Invest Score.'\n",
    "\n",
    "The constraints are implented as 'soft constraints' to account for the environmental benefits of implementing Room for the River projects as early as possible. The Room for the River ecosystem (with wildlife, fauna, etc.) benefit more from the project the earlier it is implemented. Social benefits are not considered here, though we acknowledge that they exist (e.g. people value green space in and near cities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this method with a shorter name\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE\n",
    "\n",
    "# List the names of vars to make `robustness_functions` a bit more read-able\n",
    "var_list_damage = ['A.1_Expected Annual Damage 0','A.1_Expected Annual Damage 1','A.1_Expected Annual Damage 2',\n",
    "                   'A.2_Expected Annual Damage 0','A.2_Expected Annual Damage 1','A.2_Expected Annual Damage 2',\n",
    "                   'A.3_Expected Annual Damage 0','A.3_Expected Annual Damage 1','A.3_Expected Annual Damage 2',\n",
    "                   'A.4_Expected Annual Damage 0','A.4_Expected Annual Damage 1','A.4_Expected Annual Damage 2',\n",
    "                   'A.5_Expected Annual Damage 0','A.5_Expected Annual Damage 1','A.5_Expected Annual Damage 2']\n",
    "var_list_deaths = ['A.1_Expected Number of Deaths 0','A.1_Expected Number of Deaths 1','A.1_Expected Number of Deaths 2',\n",
    "                   'A.2_Expected Number of Deaths 0','A.2_Expected Number of Deaths 1','A.2_Expected Number of Deaths 2',\n",
    "                   'A.3_Expected Number of Deaths 0','A.3_Expected Number of Deaths 1','A.3_Expected Number of Deaths 2',\n",
    "                   'A.4_Expected Number of Deaths 0','A.4_Expected Number of Deaths 1','A.4_Expected Number of Deaths 2',\n",
    "                   'A.5_Expected Number of Deaths 0','A.5_Expected Number of Deaths 1','A.5_Expected Number of Deaths 2']\n",
    "var_list_dike = ['A.1_Dike Investment Costs 0','A.1_Dike Investment Costs 1','A.1_Dike Investment Costs 2',\n",
    "                 'A.2_Dike Investment Costs 0','A.2_Dike Investment Costs 1','A.2_Dike Investment Costs 2',\n",
    "                 'A.3_Dike Investment Costs 0','A.3_Dike Investment Costs 1','A.3_Dike Investment Costs 2',\n",
    "                 'A.4_Dike Investment Costs 0','A.4_Dike Investment Costs 1','A.4_Dike Investment Costs 2',\n",
    "                 'A.5_Dike Investment Costs 0','A.5_Dike Investment Costs 1','A.5_Dike Investment Costs 2']\n",
    "var_list_rfr = ['RfR Total Costs 0', 'RfR Total Costs 1', 'RfR Total Costs 2']\n",
    "var_list_evac = ['Expected Evacuation Costs 0', 'Expected Evacuation Costs 1', 'Expected Evacuation Costs 2']\n",
    "\n",
    "# These functions need to only return one score value...\n",
    "robustness_functions = [\n",
    "    ScalarOutcome('Damage Score', variable_name = var_list_damage,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(0,4e16)),    \n",
    "    ScalarOutcome('Deaths Score', variable_name = var_list_deaths,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(0,8.5e19)),\n",
    "    ScalarOutcome('Dike Invest Score', variable_name = var_list_dike,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(1e18,1.3e7)),\n",
    "    ScalarOutcome('RfR Invest Score', variable_name = var_list_rfr,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(2e16,9.1e17)),\n",
    "    ScalarOutcome('Evac Score', variable_name = var_list_evac,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(0,2.5e12)),\n",
    "]\n",
    "\n",
    "constraints = [Constraint(\"discount_for_rfr_0\", outcome_names=\"RfR Total Costs 0\",\n",
    "                          function=lambda x:max(0, x-426.24)),\n",
    "               Constraint(\"discount_for_rfr_1\", outcome_names=\"RfR Total Costs 1\",\n",
    "                          function=lambda x:max(0, x-284.16)),\n",
    "               Constraint(\"discount_for_rfr_2\", outcome_names=\"RfR Total Costs 2\",\n",
    "                          function=lambda x:max(0, x-142.08))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run MORO without the hypervolume indicator. We chose 10 scenarios and 200 nfes here so as to be a small set. **We can find the total number of possiblities – see #9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ema_workbench.em_framework.optimization import EpsilonProgress\n",
    "# from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "# BaseEvaluator.reporting_frequency = 0.1\n",
    "\n",
    "# epsilons = [0.05,]*len(robustness_functions)\n",
    "\n",
    "# # Record the run time\n",
    "# start = time.time()\n",
    "\n",
    "# # Run MORO\n",
    "# with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "#     results, convergence = evaluator.robust_optimize(robustness_functions,\n",
    "#                                                      scenarios=10,\n",
    "#                                                      nfe=200,\n",
    "#                                                      epsilons=epsilons,\n",
    "#                                                      convergence=[EpsilonProgress()],\n",
    "#                                                      convergence_freq=1,\n",
    "#                                                      constraint=constraints\n",
    "#                                                     )\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))\n",
    "\n",
    "# # Write the results so this step can be skipped when doing multiple analyzes\n",
    "# with open('Outcomes/initial_Pareto_policies.pkl', 'wb') as file_pi:\n",
    "#     pickle.dump(results, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "with open('Outcomes/initial_Pareto_policies.pkl', 'rb') as file_pi:\n",
    "    results = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can some policies somewhere on a Pareto front, we can run them under more scenarios (scenario discovery) and see the variance of their values across those scenarios. We use 50 scenarios just as a sample fo the scenario space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the levers for each Pareto policy\n",
    "# policies = []\n",
    "# for row in range(results.shape[0]):\n",
    "#     policies.append(\n",
    "#         # Do not include the damage scores\n",
    "#         Policy(name=row, **results.iloc[row, :-5].to_dict())\n",
    "#     )\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "#     results = evaluator.perform_experiments(scenarios=50,policies=policies)\n",
    "    \n",
    "# end = time.time()\n",
    "# print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))\n",
    "\n",
    "# # Write the results so this step can be skipped when doing multiple analyzes\n",
    "# with open('Outcomes/epsilon_results.pkl', 'wb') as file_pi:\n",
    "#     pickle.dump(results, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "with open('Outcomes/epsilon_results.pkl', 'rb') as file_pi:\n",
    "    results = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these outcomes, we can find the robustness scores again and then look for the maximum interquartile range to find our $o$ _noise-adjusted $\\epsilon$ (epsilon) values_ (5 here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "\n",
    "outcomes = pd.DataFrame(outcomes)\n",
    "experiments = pd.DataFrame(experiments)\n",
    "results = experiments.join(outcomes)\n",
    "results = results.drop(columns=\"model\")\n",
    "\n",
    "# Aggregate across time and space\n",
    "aggregate_outcomes(outcomes, \"Expected Annual Damage\")\n",
    "aggregate_outcomes(outcomes, \"Dike Investment Costs\")\n",
    "aggregate_outcomes(outcomes, \"Expected Number of Deaths\")\n",
    "aggregate_outcomes(outcomes, \"RfR Total Costs\")\n",
    "aggregate_outcomes(outcomes, \"Expected Evacuation Costs\")\n",
    "\n",
    "everything = pd.DataFrame(experiments[\"policy\"]).join(outcomes)\n",
    "\n",
    "# Find the robustness scores\n",
    "robust_values = everything.groupby(\n",
    "    by=[\"policy\"]).apply(robustness).iloc[:, -5:]\n",
    "\n",
    "# Finally, find the IQR ranges that are our 'noise-adjusted epsilon values'\n",
    "ranges = robust_values.apply(sp.stats.iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Expected Annual Damage       3.287533e+15\n",
       "Total Dike Investment Costs        3.660080e+18\n",
       "Total Expected Number of Deaths    5.482093e+05\n",
       "Total RfR Total Costs              1.096303e+17\n",
       "Total Expected Evacuation Costs    4.118847e+10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Expected Annual Damage       3.897572e+16\n",
       "Total Dike Investment Costs        8.371133e+19\n",
       "Total Expected Number of Deaths    1.127772e+07\n",
       "Total RfR Total Costs              9.080500e+17\n",
       "Total Expected Evacuation Costs    2.421692e+12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_ranges_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Expected Annual Damage       0.000000e+00\n",
       "Total Dike Investment Costs        1.096392e+18\n",
       "Total Expected Number of Deaths    0.000000e+00\n",
       "Total RfR Total Costs              2.113227e+16\n",
       "Total Expected Evacuation Costs    0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_ranges_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save computation time, we are going to look at a subset of the output space. We already know from the first step **(LINK)** that the model is most senstitive to `A.1_pfail` and `A.3_pfail`. However, we also know that implementing any projects there will reduce the actual _risk_. Any dike heightening should strengthen the dikes there, which should lower the values, but the model does not currently account for such projects.\n",
    "\n",
    "Regardless, we will find optimal solutions in these worst-case scenarios. We assume that if our policies can prepare us for the worst, then they will also perform in better conditions. Later, we will test and validate these assumptions. It is also important to note that we already found any policies will improve upon the base case's outcomes (the do-nothing case).\n",
    "\n",
    "Therefore, we will limit our model's uncertainties to this worst-case space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From CART Analysis for deaths and damages\n",
    "\n",
    "dike_model.uncertainties['A.1_pfail'] = RealParameter('A.1_pfail', 0, 0.367)\n",
    "dike_model.uncertainties['A.3_pfail'] = RealParameter('A.3_pfail', 0, 0.226)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run MORO\n",
    "\n",
    "And now we can run the main computationally expensive MORO! Since we  are looking at our worst-case uncertainty space, we are confident in running the experiment for only 50 scenarios (compare to the **HOW MANY** possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework import sample_uncertainties\n",
    "\n",
    "n_scenarios = 50\n",
    "scenarios = sample_uncertainties(dike_model, n_scenarios)\n",
    "nfe = int(20000)\n",
    "\n",
    "# Create a filename for saving (and loading if we need)\n",
    "filename = 'Outcomes/MORO_s' + str(n_scenarios) + '_nfe' + str(nfe) + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] generation 0: 0/101 nfe\n",
      "[MainProcess/INFO] generation 1: 100/101 nfe\n",
      "[MainProcess/INFO] optimization completed, found 1 solutions\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.45867 minutes\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "BaseEvaluator.reporting_frequency = 0.1\n",
    "\n",
    "epsilons = ranges.values\n",
    "convergence = [HyperVolume(hyp_ranges_min, hyp_ranges_max),\n",
    "               EpsilonProgress()]\n",
    "\n",
    "# Time the run\n",
    "start = time.time()\n",
    "\n",
    "# Run MORO\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results, convergence = evaluator.robust_optimize(robustness_functions,\n",
    "                                                     scenarios=scenarios,\n",
    "                                                     nfe=nfe,\n",
    "                                                     epsilons=epsilons,\n",
    "                                                     convergence=convergence,\n",
    "                                                     convergence_freq=20,\n",
    "                                                     logging_freq=1,\n",
    "                                                     constraint=constraints\n",
    "                                                     )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))\n",
    "\n",
    "# Save the run results\n",
    "with open(filename, 'wb') as file_pi:\n",
    "    pickle.dump((results, convergence), file_pi)\n",
    "    \n",
    "# Record the runtime in a separate notebook for benchmarking\n",
    "time_str = \"Time: \" + str((end - start)/60) + \" minutes\\t Scenarios: \" + \\\n",
    "                str(n_scenarios) + \"\\t NFEs: \" + str(nfe) + \"\\n\"\n",
    "with open('Outcomes/latest_time.tsv', 'a') as f:\n",
    "    f.write(time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "results, convergence = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 4. Evaluate Convergence\n",
    "\n",
    "If the optimization does not converge, then the results that we have found are not very useful. Let's check them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, our $\\epsilon$ (epsilon) values do seem to converge around 12000 nfes. Unfortunately, the hypervolume indicator remains at 0. We hypothesize two factors that contribute to this:\n",
    "1. The maximum value we set for the hypervolume may be so large that the hypervolume is so small relative to the total space that it is rounded to 0.00.\n",
    "2. The maximum value is not large enough to capture the optimization outcome robustness scores.\n",
    "\n",
    "Outside of these notebooks, we tested smaller sample runs with different expected ranges for the hypervolume. With `hyp_ranges_max` multiplied by between $10^{20}$ to $10^{23}$, we were able to see the value be defined between 0 and 1 (using some 'dirty hacks' to use the policies from the above run as the initial population for further optimization). Any higher values would yield 1 immediately. Thus, we cannot yet claim that the hypervolume indicator has shown convergence for our problem.\n",
    "\n",
    "This is not to say we are not confident in our results. While two indicators could have been useful to understand our optimization, we expect that the hypervolume will require further debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Checking for Hypervolume Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we are going to run MORO again, but we want to initialize the optimizations with the policies we already found as initial policies (rather than starting from scratch again. This isn't supported yet by EMAworkbench, but we're submitted an issue to try and implement this in the future. The quickest way to achieve this is with a 'dirty hack' inside `platypus.algorithms.AbstractGeneticAlgorithm.initialize`.\n",
    "\n",
    "```\n",
    "def initialize(self):\n",
    "        self.population = [self.generator.generate(self.problem) for _ in range(self.population_size)]\n",
    "        self.evaluate_all(self.population)\n",
    "```\n",
    "\n",
    "We can comment out where `self.population` is initialized for the first time, and replace it with our own. However, we will need to create a list that is syntatically compatible with platypus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Create a list of solutions to feed back into platypus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice for only the actual 31 levers (not the outputs)\n",
    "pareto_policies = results.iloc[:,:-5]\n",
    "pareto_solutions = []\n",
    "# number of Pareto policies that we have\n",
    "num_paretos = pareto_policies.shape[0]\n",
    "\n",
    "# We need a little function to convert the levers into a format for platypus\n",
    "def lever_to_platypus_variables(n,lever):\n",
    "    variable = []\n",
    "    \n",
    "    # 15 is evac, 16 and higher are dike heights from 0-9 (four binary digits); all other are 0 or 1\n",
    "    if n == 15:\n",
    "        lever = '{0:03b}'.format(lever)\n",
    "    elif n >= 16:\n",
    "        lever = '{0:04b}'.format(lever)\n",
    "    else:\n",
    "        lever = '{0:01b}'.format(lever)\n",
    "        \n",
    "    for char in lever:\n",
    "        variable.append(char == '1')\n",
    "        \n",
    "    return variable\n",
    "\n",
    "from ema_workbench.em_framework.optimization import (to_robust_problem)\n",
    "from platypus import (EpsNSGAII)\n",
    "\n",
    "# Create policies properly in platypus grammar \n",
    "problem = to_robust_problem(dike_model, scenarios, robustness_functions, constraints=constraints,)\n",
    "optimizer = EpsNSGAII(problem, epsilons, nfe=nfe,convergence=convergence)\n",
    "\n",
    "# generate as many solutions as we have Pareto policies (this step is mostly for proper syntax)\n",
    "init_policies = [optimizer.generator.generate(optimizer.problem) for n in range(num_paretos)]\n",
    "\n",
    "for row_num in range(num_paretos):\n",
    "    pareto_solultion = []\n",
    "    \n",
    "    for n, lever in enumerate(pareto_policies.iloc[row_num,:]):\n",
    "        lever = lever_to_platypus_variables(n,lever)\n",
    "        pareto_solultion.append(lever)\n",
    "    \n",
    "    # Write these good solutions into this list\n",
    "    init_policies[row_num].variables = pareto_solultion\n",
    "    \n",
    "import dill as pickle\n",
    "with open('Outcomes/Pareto_solutions.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(init_policies, file_pi)\n",
    "# print(init_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Outcomes/Pareto_solutions.pkl', 'rb') as file_pi:\n",
    "#     init_policies = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run MORO again with our adjusted `hyp_ranges_max` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] generation 0: 0/1 nfe\n",
      "[MainProcess/INFO] optimization completed, found 1 solutions\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.79088 minutes\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "BaseEvaluator.reporting_frequency = 0.1\n",
    "\n",
    "epsilons = ranges.values\n",
    "convergence = [HyperVolume(hyp_ranges_min, hyp_ranges_max*1.1e10),\n",
    "               EpsilonProgress()]\n",
    "\n",
    "n_scenarios = 1\n",
    "scenarios = sample_uncertainties(dike_model, n_scenarios)\n",
    "nfe = int(1)\n",
    "\n",
    "# Time the run\n",
    "start = time.time()\n",
    "\n",
    "# Run MORO\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results, convergence = evaluator.robust_optimize(robustness_functions,\n",
    "                                                     scenarios=scenarios,\n",
    "                                                     nfe=nfe,\n",
    "                                                     epsilons=epsilons,\n",
    "                                                     convergence=convergence,\n",
    "                                                     convergence_freq=20,\n",
    "                                                     logging_freq=1,\n",
    "                                                     constraint=constraints\n",
    "                                                     )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))\n",
    "\n",
    "# Save the run results\n",
    "with open('Outcomes/Hypervolume_check.pkl', 'wb') as file_pi:\n",
    "    pickle.dump((results, convergence), file_pi)\n",
    "    \n",
    "# Record the runtime in a separate notebook for benchmarking\n",
    "time_str = \"Time: {:0.5f}\".format((end - start)/60) + \" minutes\\t Scenarios: \" + \\\n",
    "                str(n_scenarios) + \"\\t NFEs: \" + str(nfe) + \"\\n\"\n",
    "with open('Outcomes/latest_time.tsv', 'a') as f:\n",
    "    f.write(time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, convergence = pickle.load(open('Outcomes/Hypervolume_check.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these policies compare to the previous set on the Pareto front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_RfR 0</th>\n",
       "      <th>0_RfR 1</th>\n",
       "      <th>0_RfR 2</th>\n",
       "      <th>1_RfR 0</th>\n",
       "      <th>1_RfR 1</th>\n",
       "      <th>1_RfR 2</th>\n",
       "      <th>2_RfR 0</th>\n",
       "      <th>2_RfR 1</th>\n",
       "      <th>2_RfR 2</th>\n",
       "      <th>3_RfR 0</th>\n",
       "      <th>...</th>\n",
       "      <th>A.4_DikeIncrease 1</th>\n",
       "      <th>A.4_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 0</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "      <th>Damage Score</th>\n",
       "      <th>Deaths Score</th>\n",
       "      <th>Dike Invest Score</th>\n",
       "      <th>RfR Invest Score</th>\n",
       "      <th>Evac Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.611307e+16</td>\n",
       "      <td>1.238108e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_RfR 0  0_RfR 1  0_RfR 2  1_RfR 0  1_RfR 1  1_RfR 2  2_RfR 0  2_RfR 1  \\\n",
       "0        0        0        0        1        1        1        0        1   \n",
       "\n",
       "   2_RfR 2  3_RfR 0  ...  A.4_DikeIncrease 1  A.4_DikeIncrease 2  \\\n",
       "0        0        0  ...                   0                   3   \n",
       "\n",
       "   A.5_DikeIncrease 0  A.5_DikeIncrease 1  A.5_DikeIncrease 2  Damage Score  \\\n",
       "0                   2                   0                   4           0.0   \n",
       "\n",
       "   Deaths Score  Dike Invest Score  RfR Invest Score  Evac Score  \n",
       "0           0.0       9.611307e+16      1.238108e+16         0.0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_RfR 0</th>\n",
       "      <th>0_RfR 1</th>\n",
       "      <th>0_RfR 2</th>\n",
       "      <th>1_RfR 0</th>\n",
       "      <th>1_RfR 1</th>\n",
       "      <th>1_RfR 2</th>\n",
       "      <th>2_RfR 0</th>\n",
       "      <th>2_RfR 1</th>\n",
       "      <th>2_RfR 2</th>\n",
       "      <th>3_RfR 0</th>\n",
       "      <th>...</th>\n",
       "      <th>A.2_DikeIncrease 2</th>\n",
       "      <th>A.3_DikeIncrease 0</th>\n",
       "      <th>A.3_DikeIncrease 1</th>\n",
       "      <th>A.3_DikeIncrease 2</th>\n",
       "      <th>A.4_DikeIncrease 0</th>\n",
       "      <th>A.4_DikeIncrease 1</th>\n",
       "      <th>A.4_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 0</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_RfR 0  0_RfR 1  0_RfR 2  1_RfR 0  1_RfR 1  1_RfR 2  2_RfR 0  2_RfR 1  \\\n",
       "0        1        0        0        1        1        0        0        1   \n",
       "\n",
       "   2_RfR 2  3_RfR 0  ...  A.2_DikeIncrease 2  A.3_DikeIncrease 0  \\\n",
       "0        0        0  ...                   3                   1   \n",
       "\n",
       "   A.3_DikeIncrease 1  A.3_DikeIncrease 2  A.4_DikeIncrease 0  \\\n",
       "0                   7                   0                   9   \n",
       "\n",
       "   A.4_DikeIncrease 1  A.4_DikeIncrease 2  A.5_DikeIncrease 0  \\\n",
       "0                   6                   2                   3   \n",
       "\n",
       "   A.5_DikeIncrease 1  A.5_DikeIncrease 2  \n",
       "0                   2                   6  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuss results\n",
    "\n",
    "# Unfortunately, this doesn't work yet. The policies are not neatly fed to platypus (and then read back as Policy objects)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
