{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "\n",
    "# Week 4 - Multi-objective robust decision making (MORDM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise demostrates the application of MORDM on the lake model, which was used in earlier exercises.\n",
    "\n",
    "MORDM has four main steps:\n",
    "\n",
    "(i)\t    **problem formulation** based on a systems analytical problem definition framework \n",
    "\n",
    "(ii)\t**searching** for candidate solutions that optimize multiple objectives by using multi-objective evolutionary algorithms \n",
    "\n",
    "(iii)\tgenerating an ensemble of scenarios to **explore** the effects of uncertainties \n",
    "\n",
    "(iv)\tusing **scenario discovery** to detect the vulnerabilities of candidate solutions and improving thecandidate solutions\n",
    "\n",
    "\n",
    "\n",
    "## Step 1: Problem formulation\n",
    "### Lake Model\n",
    "\n",
    "Remember the lake problem used in the assignments of Week 2. The lake problem is a hypothetical case where the inhabitants of a lake town decide on the amount of annual pollution they release into a lake. It the pollution in the lake passes a threshold, it will suffer irreversible eutrophication.\n",
    "\n",
    "The lake problem has 4 **outcome indicators**: \n",
    "   - **max_P**: maximum pollution over time, to be minimized\n",
    "   - **utility**: economic benefits obtained from polluting the lake, to be maximized\n",
    "   - **inertia**: the percentage of significant annual changes in the anthropogenic pollution rate, to be minimized\n",
    "   - **reliability**: the percentage of years where the pollution level is below the critical threshold, to be maximized\n",
    "    \n",
    "See the lake mode lexercise for the formulation of these outcome variables.\n",
    "\n",
    "The lake problem is characterized by both stochastic uncertainty and **deep uncertainty**. The stochastic uncertainty arises from the natural inflow. To reduce this stochastic uncertainty, multiple replications are performed and the average over the replication is taken. Deep uncertainty is presented by uncertainty about the mean $\\mu$ and standard deviation $sigma$ of the lognormal distribution characterizing the natural inflow, the natural removal rate of the lake $\\beta$, the natural recycling rate of the lake $q$, and the discount rate $\\delta$. The table below specifies the ranges for the deeply uncertain factors, as well as their best estimate or default values. \n",
    "\n",
    "|Parameter\t|Range\t        |Default value|\n",
    "|-----------|--------------:|------------:|\n",
    "|$\\mu$    \t|0.01 – 0.05\t|0.02         |\n",
    "|$\\sigma$\t|0.001 – 0.005 \t|0.0017       |\n",
    "|$b$      \t|0.1 – 0.45\t    |0.42         |\n",
    "|$q$\t    |2 – 4.5\t    |2            |\n",
    "|$\\delta$\t|0.93 – 0.99\t|0.98         |\n",
    "\n",
    "\n",
    "The lake problem in the exercise of Week 2 had 100 decision **levers**, meaning that the decision makers independently decide on the amount of anthropogenic pollution at every time step (100) over 100 days. Then a 'policy' was a set of values for these 100 levers, which you composed by sampling from the range [0, 0.1].   \n",
    "\n",
    "In this exercise, we will use a **closed loop** version of the lake model, meaning that $a_t$ (anthropogenic pollution) is dependent on $X_t$ (the pollution level at time t). For instance, the rate of anthropogenic pollutions is lowered if the pollution level is approaching a critical threshold. Here, we use \"cubic radial basis functions\" following [Quinn et al. 2017](http://www.sciencedirect.com/science/article/pii/S1364815216302250) and formulate $a_t$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    a_{t} =  min\\Bigg(max\\bigg(\\sum\\limits_{j=1}^{n} w_{j}\\left\\vert{\\frac{X_{t,i}-c_{j}}{r_{j}}}\\right\\vert^3, 0.01\\bigg), 0.1\\Bigg) \\\\\n",
    "    s.t. \\\\\n",
    "    -2 \\leq c_{j} \\leq 2 \\\\\n",
    "    0 \\leq r_{j} \\leq 2 \\\\ \n",
    "    0 \\leq w_{j} \\leq 1 \\\\\n",
    "    \\sum\\limits_{j=1}^{n} w_{j} = 1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The parameters that define this function also define the pollution strategy over time. Hence, the decision **levers** are the five parameters of this functions, namely $c_1$, $c_2$, $r_1$, $r_2$ and $w_1$. ($w_2$ = 1 - $w_1$).\n",
    "\n",
    "Note:: i is index for the realization, given m realizations; j is the index for the radial basis function, given 2 radial basis functions. \n",
    "\n",
    "**To formulate this problem, do the following:**\n",
    "\n",
    "**1) Define a function for the anthropogenic pollution.**\n",
    "\n",
    "**2) adapt the lake model function, which is the 'system model' for this problem, from your previous exercise. Modify the lake model formulation according to the new decision making structure (levers).**\n",
    "\n",
    "tip: in this formulation the decision is specified by a decision rule. You specify the decision rule using the radial basis functions. An example of such a rule is shown in figure 2 in Quinn et al (2017). Since you are making the actual release decision in a given year conditional on the observed pollution in the lake in the previous year, your actual release will differ from one stochastic realization to the next. This means that you have to ensure that you adapt the inertia objective accordingly! \n",
    "\n",
    "**3) Create an ema_workbench interface for this problem, with corresponding uncertainties, levers and outcomes.**\n",
    "\n",
    "\n",
    "try to work it out yourself first. If you struggle, have a look [here](https://waterprogramming.wordpress.com/author/jhkwakkel/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Searching for candidate solutions\n",
    "\n",
    "In the second step of MORDM, candidate strategies are identified which are pareto optimal conditional on a reference scenario. These candiate strategies are identified through *search* with multi-objective evolutionary algorithms, that iteratively evaluate a large number of alternatives on multiple objectives until they find the best candidates. For instance, when we optimize the lake model levers, the lake model function will be called for each candidate evaluation, and the corresponding four objective values will be generated. \n",
    "\n",
    "*Platypus* is python package developed by David Hadka (http://platypus.readthedocs.io/en/latest/) for multi-objective optimization. It allows an explicit specification of the problem components (levers, objectives, constraints). The package includes several multi-objective evolutionary algorithms, therefore the users can choose the algorithm they wish to use. \n",
    "\n",
    "you can use pip to install it:\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/Project-Platypus/Platypus.git\n",
    "\n",
    "```\n",
    "\n",
    "In this exercise, I recommend to use Platypus with the ε-NSGAII algorithm, since it is shown to outperform many MOEA’s. For other algortihms, see the documentation of Platypus. For a comparison of them, you can have a look at \n",
    "\n",
    "    Reed, P. M., D. Hadka, J. D. Herman, J. R. Kasprzyk, and J. B. Kollat. 2013. \"Evolutionary multiobjective optimization in water resources: The past, present, and future.\"  Advances in Water Resources 51:438-456. doi: http://dx.doi.org/10.1016/j.advwatres.2012.01.005.\n",
    "    \n",
    "    \n",
    "Take the model interface deveoped in the previous step and use the optimization functionality of the workbench to identify the pareto approximate set of solutions. Try the following:\n",
    "* change the epsilon values between 0.01 and 0.1, what changes, why?\n",
    "* change the number of function evaluations from 1000 to 10.000 (this requires using multiprocessing unless you are very patient). What is the difference? You can use the convergence as explained in the water programming tutorial to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As an exercise, you can plot the tradeoffs you have found on a parallel plot. Note that the values on each axis should be normalized to ensure a reasonable comparison.**\n",
    "\n",
    "We can visualize these tradeoffs on **parallel coordinate plots**, which have a column (vertical axis) for each objective. Each solution is represetned by a line on this plot, which crosses the objective axes at the corresponsing value. You can use the [parcoords functionality](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/analysis/parcoords.html) for this that comes with the ema_workbench. Ensure that the direction of desirability is the same for the four objectives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this plot tell us about the tradeoffs and conflicting objectives?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Re-evaluate candidate solutions under uncertainty\n",
    "\n",
    "We now have a large number of candidate solutions (policies), we can re-evaluate them over the various deeply uncertaint factors to assess their robustness against uncertainties.\n",
    "\n",
    "For this robustness evaluation, we need to explore the scenarios for each solution. It means that, if we would like to run for instance 1000 scenarios for each solution, we might have to execute a very large number of runs.\n",
    "\n",
    "Here, to simplify the case, let's suppose that decision makers have a hard constrain on *reliability*. No solution with less than 90% reliability is acceptable for them. Therefore, we can reduce the size of the solution set according to this constraint. \n",
    "\n",
    "**Apply this constraint of reliability on the results, and create a new dataframe named new_reults**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From new_results, which is the reduced dataframe of candidate solutions, make a list of policies in a fromat that can be inputed to the *perform_experiments* function of the EMA workbench.**\n",
    "\n",
    "*hint: you need to transform each policy to a dict, and then use this dict as input for the Policy class that comes with the workbench*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform 1000 scenarios for each of the policy options. Depending on how many solutions are left after implementing the constraint, consider using multiprocessing or ipyparallel to speed up calculations.**\n",
    "\n",
    "If you want to use ipyprallel, don't forget to start ipcluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the **robustness** of each of the policy options based on these scenario results. We can calculate the robustness of a policy option in terms of its performance on an outcome indicator across the 1000 scenarios. In other words, we can identify how robust a policy is in terms of each outcome indicator, and investigate the robustness tradeoffs.  \n",
    "\n",
    "There are multiple metrics to quantify robustness. On of them is the *signal to noise ratio*, which is simply the mean of a dataset divided by its standard deviation. For instance, for an outcome indicator to be maximized, we prefer a high average value across the scenarios, and a low standard deviation, implying a narrow uncertaintiy range. Therefore, we want to maximize the signal-to-noise ratio. For an outcome indicator to be minimized, a lower mean and a lower standard deviation is preferred. Therefore the formulation shoudl be different.\n",
    "\n",
    "**Write a function to calculate the signal-to-noise ratio for both kinds of outcome indicators. Calculate the signal-to-noise ratios for each outcome and each policy option. Plot the tradeoffs on a parallel plot. Which solutions look like a good compromise policy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another robustness metric is **maximum regret**, calculated again for each policy and for each outcome indicator. *Regret* is defined for each policy under each scenario, as the difference between the performance of that scenario and the berformance of a no-regret or refeence policy. The *maximum regret*  is then the maximum of such regret values across all scenarios. We off course favor policy options with low *maximum regret* values. (You can find furter explanation in the slides of the Advanced System Dynamics course.)\n",
    "\n",
    "**Write a function to calculate the maximum regret for both kinds of outcome indicators. Calculate the maximum regret values for each outcome and each policy option. Plot the tradeoffs on a parallel plot. Which solutions look like a good compromise policy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
