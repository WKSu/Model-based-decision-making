{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenRivers MORO\n",
    "\n",
    "_Description_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import every package we need\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario, SequentialEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments, optimize\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging, utilities\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the random policies scenarios to look at our entire input-output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "#     experiments, outcomes = evaluator.perform_experiments(\n",
    "#         scenarios = 10,\n",
    "#         policies = 4,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.util.utilities import (save_results, load_results)\n",
    "\n",
    "results = load_results('outcomes/400Scenarios75Policies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MORO\n",
    "\n",
    "_Why?_\n",
    "\n",
    "|Outcome of interest| Threshold  |\n",
    "|-------------------|------------|\n",
    "| Deaths            | $\\leq$ 0.x|\n",
    "| Damage            | $\\leq$ 0.x |\n",
    "| Dike Costs        | $\\leq$ 0.x|   \n",
    "| RfR Costs         | $\\geq$ 0.x|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "from model.dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from model.problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define robustness functions\n",
    "\n",
    "# Rebustness score\n",
    "def robustness(data):\n",
    "    ''' \n",
    "    We want a function that returns 0 for the outcome to be in the range that we want and higher otherwise.\n",
    "    \n",
    "    Takes in an array and returns a score for each value of the same array.\n",
    "    '''\n",
    "    mean = np.mean(data)\n",
    "    iqr = sp.stats.iqr(data) + 1\n",
    "    \n",
    "    return mean * iqr\n",
    "\n",
    "# Initialize some vars to make `robustness_functions` a bit more read-able\n",
    "var_list_damage = ['A.1_Expected Annual Damage 0','A.1_Expected Annual Damage 1','A.1_Expected Annual Damage 2',\n",
    "                   'A.2_Expected Annual Damage 0','A.2_Expected Annual Damage 1','A.2_Expected Annual Damage 2',\n",
    "                   'A.3_Expected Annual Damage 0','A.3_Expected Annual Damage 1','A.3_Expected Annual Damage 2',\n",
    "                   'A.4_Expected Annual Damage 0','A.4_Expected Annual Damage 1','A.4_Expected Annual Damage 2',\n",
    "                   'A.5_Expected Annual Damage 0','A.5_Expected Annual Damage 1','A.5_Expected Annual Damage 2']\n",
    "var_list_deaths = ['A.1_Expected Number of Deaths 0','A.1_Expected Number of Deaths 1','A.1_Expected Number of Deaths 2',\n",
    "                   'A.2_Expected Number of Deaths 0','A.2_Expected Number of Deaths 1','A.2_Expected Number of Deaths 2',\n",
    "                   'A.3_Expected Number of Deaths 0','A.3_Expected Number of Deaths 1','A.3_Expected Number of Deaths 2',\n",
    "                   'A.4_Expected Number of Deaths 0','A.4_Expected Number of Deaths 1','A.4_Expected Number of Deaths 2',\n",
    "                   'A.5_Expected Number of Deaths 0','A.5_Expected Number of Deaths 1','A.5_Expected Number of Deaths 2']\n",
    "var_list_dike = ['A.1_Dike Investment Costs 0','A.1_Dike Investment Costs 1','A.1_Dike Investment Costs 2',\n",
    "                 'A.2_Dike Investment Costs 0','A.2_Dike Investment Costs 1','A.2_Dike Investment Costs 2',\n",
    "                 'A.3_Dike Investment Costs 0','A.3_Dike Investment Costs 1','A.3_Dike Investment Costs 2',\n",
    "                 'A.4_Dike Investment Costs 0','A.4_Dike Investment Costs 1','A.4_Dike Investment Costs 2',\n",
    "                 'A.5_Dike Investment Costs 0','A.5_Dike Investment Costs 1','A.5_Dike Investment Costs 2']\n",
    "var_list_rfr = ['RfR Total Costs 0', 'RfR Total Costs 1', 'RfR Total Costs 2']\n",
    "var_list_evac = ['Expected Evacuation Costs 0', 'Expected Evacuation Costs 1', 'Expected Evacuation Costs 2']\n",
    "\n",
    "MAXIMIZE = ScalarOutcome.MAXIMIZE\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE\n",
    "\n",
    "# These functions need to only return one value...\n",
    "\n",
    "robustness_functions = [\n",
    "    ScalarOutcome('Damage Score', function = robustness, kind = MINIMIZE, variable_name = var_list_damage),    \n",
    "    ScalarOutcome('Deaths Score', function = robustness, kind = MINIMIZE, variable_name = var_list_deaths),\n",
    "    ScalarOutcome('Dike Invest Score', function = robustness, kind = MINIMIZE, variable_name = var_list_dike),\n",
    "    ScalarOutcome('RfR Invest Score', variable_name = var_list_rfr, function = robustness, kind = MINIMIZE),\n",
    "    ScalarOutcome('Evac Score', variable_name = var_list_evac, function = robustness, kind = MINIMIZE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework import sample_uncertainties\n",
    "\n",
    "n_scenarios = 1\n",
    "scenarios = sample_uncertainties(dike_model, n_scenarios)\n",
    "nfe = int(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] generation 0: 0/1 nfe\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "robustness() takes 1 positional argument but 15 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8b1692614345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                         \u001b[0mnfe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                         \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                         convergence=convergence)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ema_workbench/em_framework/evaluators.py\u001b[0m in \u001b[0;36mrobust_optimize\u001b[0;34m(self, robustness_functions, scenarios, algorithm, nfe, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                                \u001b[0mconvergence_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvergence_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                                logging_freq=logging_freq, **kwargs)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ema_workbench/em_framework/evaluators.py\u001b[0m in \u001b[0;36mrobust_optimize\u001b[0;34m(model, robustness_functions, scenarios, evaluator, algorithm, nfe, convergence, constraints, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     return _optimize(problem, evaluator, algorithm, convergence,\n\u001b[0;32m--> 585\u001b[0;31m                      int(nfe), convergence_freq, logging_freq, **kwargs)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ema_workbench/em_framework/optimization.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(problem, evaluator, algorithm, convergence, nfe, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     with temporary_filter(name=[callbacks.__name__,\n\u001b[1;32m    828\u001b[0m                                 evaluators.__name__], level=INFO):\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     results = to_dataframe(optimizer, problem.parameter_names,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/platypus/core.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, condition, callback)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_frequency\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlast_log\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_frequency\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNSGAII\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/platypus/algorithms.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/platypus/core.py\u001b[0m in \u001b[0;36mevaluate_all\u001b[0;34m(self, solutions)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_EvaluateJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munevaluated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# if needed, update the original solution with the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ema_workbench/em_framework/evaluators.py\u001b[0m in \u001b[0;36mevaluate_all\u001b[0;34m(self, jobs, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mevaluate_robust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ema_workbench/em_framework/optimization.py\u001b[0m in \u001b[0;36mevaluate_robust\u001b[0;34m(jobs_collection, experiments, outcomes, problem)\u001b[0m\n\u001b[1;32m    424\u001b[0m             data = [outcomes[var_name][logical] for var_name in\n\u001b[1;32m    425\u001b[0m                     rf.variable_name]\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0mjob_outcomes_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mjob_outcomes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: robustness() takes 1 positional argument but 15 were given"
     ]
    }
   ],
   "source": [
    "from ema_workbench import ema_logging\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, \n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "BaseEvaluator.reporting_frequency = 0.1\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "epsilons = [0.05,]*len(robustness_functions)\n",
    "convergence = [HyperVolume(minimum=[0,0,0], maximum=[1.1, 1.1, 1.1]),\n",
    "              EpsilonProgress()]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.robust_optimize(robustness_functions,\n",
    "                                        scenarios = scenarios,\n",
    "                                        nfe=nfe,\n",
    "                                        epsilons=epsilons,\n",
    "                                        convergence=convergence)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate $\\epsilon$-convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate under more scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policies = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios = 1000, policies = policies)\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate regret compared to a base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1)[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "\n",
    "# makes it easier to identify the policy associated with each line\n",
    "# in the parcoords plot\n",
    "# data['policy'] = data.index.astype(\"float64\")\n",
    "\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see striking differences between blue and orange (1 and 3) and green and red (5 and 8). The first two options have low regret on the first three objectives, but higher regret on utility. For the second two options it is reversed\n",
    "\n",
    "Note that we have been looking at the maximum regret. I also saved the distribution of regret over the set of scenarios. So let's visualize this and see what we can learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "policy_regret = defaultdict(dict)\n",
    "for key, value in overall_regret.items():\n",
    "    for policy in value:\n",
    "        policy_regret[policy][key] = value[policy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates a 2 by 2 axes grid, with a shared X and Y axis\n",
    "# accross all plots\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10,10), \n",
    "                         sharey=True, sharex=True)\n",
    "\n",
    "# to ensure easy iteration over the axes grid, we turn it\n",
    "# into a list. Because there are four plots, I hard coded\n",
    "# this. \n",
    "axes = [axes[0,0], axes[0,1],\n",
    "        axes[1,0],]\n",
    "\n",
    "# zip allows us to zip together the list of axes and the list of \n",
    "# key value pairs return by items. If we iterate over this\n",
    "# it returns a tuple of length 2. The first item is the ax\n",
    "# the second items is the key value pair.\n",
    "for ax, (policy, regret) in zip(axes, policy_regret.items()):\n",
    "    data = pd.DataFrame(regret)\n",
    "\n",
    "    # we need to scale the regret to ensure fair visual\n",
    "    # comparison. We can do that by divding by the maximum regret\n",
    "    data = data/max_regret.max(axis=0)\n",
    "    sns.boxplot(data=data, ax=ax)\n",
    "    \n",
    "    # removes top and left hand black outline of axes\n",
    "    sns.despine()\n",
    "    \n",
    "    # ensure we know which policy the figure is for\n",
    "    ax.set_title(str(policy))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
