{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenRivers MORO\n",
    "\n",
    "_Description_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import every package we need\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter, Constraint)\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario, SequentialEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments, optimize\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging, utilities\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the random policies scenarios to look at our entire input-output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "#     experiments, outcomes = evaluator.perform_experiments(\n",
    "#         scenarios = 10,\n",
    "#         policies = 4,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from /Users/jrwang/Documents/Coding/Model-based-decision-making/outcomes/400Scenarios75Policies.csv\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench.util.utilities import (save_results, load_results)\n",
    "\n",
    "results = load_results('outcomes/400Scenarios75Policies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get a sense of the expected outcomes from the outcomes to determine convergence later. Let's take a look at the outcomes of a few randomly sampled policies and scenarios here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up MORO\n",
    "\n",
    "_Why?_\n",
    "\n",
    "|Outcome of interest| Expected Range  |\n",
    "|-------------------|------------|\n",
    "| Deaths            | $\\leq$ 0.x|\n",
    "| Damage            | $\\leq$ 0.x |\n",
    "| Evacuation Costs            | $\\leq$ 0.x |\n",
    "| Dike Investment Costs        | $\\leq$ 0.x|   \n",
    "| RfR Investment Costs         | $\\geq$ 0.x|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model parameters\n",
    "from model.dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from model.problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define robustness functions\n",
    "\n",
    "# Rebustness score\n",
    "def robustness(data):\n",
    "    ''' \n",
    "    Returns a robustness score for a value you want to minimize.\n",
    "    s\n",
    "    We want a function that returns 0 for the outcome to be in the range that we want and higher otherwise.\n",
    "    \n",
    "    Takes in an array and returns a score for each value of the same array.\n",
    "    '''\n",
    "    \n",
    "    # Normalize\n",
    "    mean = np.mean(data)\n",
    "    iqr = sp.stats.iqr(data) + mean * 0.005 # Add a small number so the mean is still considered in the score rather than 0\n",
    "    score = mean * iqr\n",
    "    \n",
    "    return score\n",
    "\n",
    "def sumover_robustness(*data):\n",
    "    '''\n",
    "    Used to aggregate multiple outcomes into one robustness score.\n",
    "    \n",
    "    Input: multiple n-length (but same) arrays and sums up element-wise into a [1,n] array\n",
    "    \n",
    "    Returns: asks the robustness function to calculate a score for the [1,n] array.\n",
    "    '''\n",
    "    return robustness(sum(data))\n",
    "\n",
    "# Initialize some vars to make `robustness_functions` a bit more read-able\n",
    "var_list_damage = ['A.1_Expected Annual Damage 0','A.1_Expected Annual Damage 1','A.1_Expected Annual Damage 2',\n",
    "                   'A.2_Expected Annual Damage 0','A.2_Expected Annual Damage 1','A.2_Expected Annual Damage 2',\n",
    "                   'A.3_Expected Annual Damage 0','A.3_Expected Annual Damage 1','A.3_Expected Annual Damage 2',\n",
    "                   'A.4_Expected Annual Damage 0','A.4_Expected Annual Damage 1','A.4_Expected Annual Damage 2',\n",
    "                   'A.5_Expected Annual Damage 0','A.5_Expected Annual Damage 1','A.5_Expected Annual Damage 2']\n",
    "var_list_deaths = ['A.1_Expected Number of Deaths 0','A.1_Expected Number of Deaths 1','A.1_Expected Number of Deaths 2',\n",
    "                   'A.2_Expected Number of Deaths 0','A.2_Expected Number of Deaths 1','A.2_Expected Number of Deaths 2',\n",
    "                   'A.3_Expected Number of Deaths 0','A.3_Expected Number of Deaths 1','A.3_Expected Number of Deaths 2',\n",
    "                   'A.4_Expected Number of Deaths 0','A.4_Expected Number of Deaths 1','A.4_Expected Number of Deaths 2',\n",
    "                   'A.5_Expected Number of Deaths 0','A.5_Expected Number of Deaths 1','A.5_Expected Number of Deaths 2']\n",
    "var_list_dike = ['A.1_Dike Investment Costs 0','A.1_Dike Investment Costs 1','A.1_Dike Investment Costs 2',\n",
    "                 'A.2_Dike Investment Costs 0','A.2_Dike Investment Costs 1','A.2_Dike Investment Costs 2',\n",
    "                 'A.3_Dike Investment Costs 0','A.3_Dike Investment Costs 1','A.3_Dike Investment Costs 2',\n",
    "                 'A.4_Dike Investment Costs 0','A.4_Dike Investment Costs 1','A.4_Dike Investment Costs 2',\n",
    "                 'A.5_Dike Investment Costs 0','A.5_Dike Investment Costs 1','A.5_Dike Investment Costs 2']\n",
    "var_list_rfr = ['RfR Total Costs 0', 'RfR Total Costs 1', 'RfR Total Costs 2']\n",
    "var_list_evac = ['Expected Evacuation Costs 0', 'Expected Evacuation Costs 1', 'Expected Evacuation Costs 2']\n",
    "\n",
    "MAXIMIZE = ScalarOutcome.MAXIMIZE\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE\n",
    "\n",
    "# These functions need to only return one value...\n",
    "\n",
    "robustness_functions = [\n",
    "    ScalarOutcome('Damage Score', variable_name = var_list_damage,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(0,4e16)),    \n",
    "    ScalarOutcome('Deaths Score', variable_name = var_list_deaths,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(0,8.5e19)),\n",
    "    ScalarOutcome('Dike Invest Score', function = sumover_robustness,\n",
    "                  kind = MINIMIZE, variable_name = var_list_dike, expected_range=(1e18,1.3e7)),\n",
    "    ScalarOutcome('RfR Invest Score', variable_name = var_list_rfr,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(2e16,9.1e17)),\n",
    "    ScalarOutcome('Evac Score', variable_name = var_list_evac,\n",
    "                  function = sumover_robustness, kind = MINIMIZE, expected_range=(0,2.5e12)),\n",
    "]\n",
    "\n",
    "constraints = [Constraint(\"discount_for_rfr_0\", outcome_names=\"RfR Total Costs 0\",\n",
    "                          function=lambda x:max(0, x-426.24)),\n",
    "               Constraint(\"discount_for_rfr_1\", outcome_names=\"RfR Total Costs 1\",\n",
    "                          function=lambda x:max(0, x-284.16)),\n",
    "               Constraint(\"discount_for_rfr_2\", outcome_names=\"RfR Total Costs 2\",\n",
    "                          function=lambda x:max(0, x-142.08))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework import sample_uncertainties\n",
    "\n",
    "n_scenarios = 2\n",
    "scenarios = sample_uncertainties(dike_model, n_scenarios)\n",
    "nfe = int(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] generation 0: 0/50 nfe\n",
      "[MainProcess/INFO] optimization completed, found 7 solutions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.44087 minutes\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench import ema_logging\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, \n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "BaseEvaluator.reporting_frequency = 0.1\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "epsilons = [0.05,]*len(robustness_functions)\n",
    "convergence = [HyperVolume(minimum=[0,0,0,0,0], maximum=[4e20, 8.5e25, 1.3e20, 9.1e20, 2.5e25]),\n",
    "              EpsilonProgress()]\n",
    "# .from_outcomes(robustness_functions)\n",
    "# minimum=[0,0,0,0,0], maximum=[4e20, 8.5e25, 1.3e20, 9.1e20, 2.5e25])\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results, convergence = evaluator.robust_optimize(robustness_functions,\n",
    "                                                     scenarios = scenarios,\n",
    "                                                     nfe=nfe,\n",
    "                                                     epsilons=epsilons,\n",
    "                                                     convergence=convergence,\n",
    "                                                     convergence_freq=20,\n",
    "                                                     logging_freq = 1,\n",
    "                                                     constraint=constraints\n",
    "                                                    )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_pi = open('outcomes/MORO_trial.pkl', 'wb') \n",
    "pickle.dump((results, convergence), file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate $\\epsilon$-convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate under more scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policies = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios = 1000, policies = policies)\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate regret compared to a base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1)[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "\n",
    "# makes it easier to identify the policy associated with each line\n",
    "# in the parcoords plot\n",
    "# data['policy'] = data.index.astype(\"float64\")\n",
    "\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see striking differences between blue and orange (1 and 3) and green and red (5 and 8). The first two options have low regret on the first three objectives, but higher regret on utility. For the second two options it is reversed\n",
    "\n",
    "Note that we have been looking at the maximum regret. I also saved the distribution of regret over the set of scenarios. So let's visualize this and see what we can learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "policy_regret = defaultdict(dict)\n",
    "for key, value in overall_regret.items():\n",
    "    for policy in value:\n",
    "        policy_regret[policy][key] = value[policy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates a 2 by 2 axes grid, with a shared X and Y axis\n",
    "# accross all plots\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10,10), \n",
    "                         sharey=True, sharex=True)\n",
    "\n",
    "# to ensure easy iteration over the axes grid, we turn it\n",
    "# into a list. Because there are four plots, I hard coded\n",
    "# this. \n",
    "axes = [axes[0,0], axes[0,1],\n",
    "        axes[1,0],]\n",
    "\n",
    "# zip allows us to zip together the list of axes and the list of \n",
    "# key value pairs return by items. If we iterate over this\n",
    "# it returns a tuple of length 2. The first item is the ax\n",
    "# the second items is the key value pair.\n",
    "for ax, (policy, regret) in zip(axes, policy_regret.items()):\n",
    "    data = pd.DataFrame(regret)\n",
    "\n",
    "    # we need to scale the regret to ensure fair visual\n",
    "    # comparison. We can do that by divding by the maximum regret\n",
    "    data = data/max_regret.max(axis=0)\n",
    "    sns.boxplot(data=data, ax=ax)\n",
    "    \n",
    "    # removes top and left hand black outline of axes\n",
    "    sns.despine()\n",
    "    \n",
    "    # ensure we know which policy the figure is for\n",
    "    ax.set_title(str(policy))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
