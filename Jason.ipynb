{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenRivers MORO\n",
    "\n",
    "_Description_\n",
    "\n",
    "## Set up MORO\n",
    "\n",
    "|Outcome of interest| Threshold  |\n",
    "|-------------------|------------|\n",
    "| Deaths            | $\\leq$ 0.x|\n",
    "| Damage            | $\\leq$ 0.x |\n",
    "| Dike Costs        | $\\leq$ 0.x|   \n",
    "| RfR Costs         | $\\geq$ 0.x|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from model.problem_formulation import get_model_for_problem_formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dike_model, planning_steps = get_model_for_problem_formulation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define robustness functions\n",
    "# We want a function that returns 0 for the outcome to be in the range that we want and higher otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXIMIZE = ScalarOutcome.MAXIMIZE\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE\n",
    "\n",
    "# These functions need to only return one value...\n",
    "\n",
    "robustness_functions = [\n",
    "    ScalarOutcome('Damage Score', function = MY_FUNC, kind = MINIMIZE,\n",
    "                  variable_name=['A.1_Expected Annual Damage' ,'A.2_Expected Annual Damage',\n",
    "                                 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage']),    \n",
    "    ScalarOutcome('Deaths Score', function = MY_FUNC, kind = MINIMIZE\n",
    "                  variable_name=['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths',\n",
    "                                 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths']),\n",
    "    ScalarOutcome('Dike Invest Score', function = MY_FUNC, kind = MINIMIZE,\n",
    "                  variable_name=['A.1_Dike Investment Costs', 'A.2_Dike Investment Costs',\n",
    "                                 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs']),\n",
    "    ScalarOutcome('RfR Invest Score', variable_name=['RfR Total Costs'], function = MY_FUNC, kind = MINIMIZE),\n",
    "    ScalarOutcome('Evac Score', variable_name=['Expected Evacuation Costs'], function = MY_FUNC, kind = MINIMIZE),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dps_lake_model import lake_model\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome, ema_logging)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "lake_model = Model('lakeproblem', function = lake_model)\n",
    "\n",
    "# Define uncertainties\n",
    "lake_model.uncertainties = [RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2, 4.5),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# Define lever\n",
    "lake_model.levers = [RealParameter('c1', -2, 2),\n",
    "                        RealParameter('c2', -2, 2),\n",
    "                        RealParameter('r1', 0, 2),\n",
    "                        RealParameter('r2', 0, 2),\n",
    "                        RealParameter('w1', 0, 1)]\n",
    "\n",
    "# Define outcomes\n",
    "lake_model.outcomes = [ScalarOutcome('max_P', kind=ScalarOutcome.MINIMIZE),\n",
    "                       ScalarOutcome('utility', kind=ScalarOutcome.MAXIMIZE),\n",
    "                       ScalarOutcome('inertia', kind=ScalarOutcome.MAXIMIZE),\n",
    "                       ScalarOutcome('reliability', kind=ScalarOutcome.MAXIMIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework import sample_uncertainties\n",
    "\n",
    "n_scenarios = 2\n",
    "scenarios = sample_uncertainties(lake_model, n_scenarios)\n",
    "nfe = int(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import ema_logging\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, \n",
    "                                                     EpsilonProgress)\n",
    "from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "import time\n",
    "\n",
    "BaseEvaluator.reporting_frequency = 0.1\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "epsilons = [0.05,]*len(robustness_functions)\n",
    "convergence = [HyperVolume(minimum=[0,0,0], maximum=[1.1, 1.1, 1.1]),\n",
    "              EpsilonProgress()]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results, convergence = evaluator.robust_optimize(robustness_functions,\n",
    "                                                    scenarios = scenarios,\n",
    "                                                    nfe=nfe,\n",
    "                                                    epsilons=epsilons,\n",
    "                                                    convergence=convergence)\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate $\\epsilon$-convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "ax1.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "ax1.set_ylabel('$\\epsilon$-progress')\n",
    "ax2.plot(convergence.nfe, convergence.hypervolume)\n",
    "ax2.set_ylabel('hypervolume')\n",
    "\n",
    "ax1.set_xlabel('number of function evaluations')\n",
    "ax2.set_xlabel('number of function evaluations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate under more scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policies = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios = 1000, policies = policies)\n",
    "end = time.time()\n",
    "print(\"Time taken: {:0.5f} minutes\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate regret compared to a base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "\n",
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # create a DataFrame with all the relevent information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({outcome.name: outcomes[outcome.name], \n",
    "                         \"policy\":experiments['policy'],\n",
    "                         \"scenario\":experiments['scenario']})\n",
    "    \n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "    \n",
    "    # flatten the resulting hierarchical index resulting from \n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "    \n",
    "    # we need to control the broadcasting. \n",
    "    # max returns a 1d vector across scenario id. By passing\n",
    "    # np.newaxis we ensure that the shape is the same as the data\n",
    "    # next we take the absolute value\n",
    "    #\n",
    "    # basically we take the difference of the maximum across \n",
    "    # the row and the actual values in the row\n",
    "    #\n",
    "    outcome_regret = (data.max(axis=1)[:, np.newaxis] - data).abs()\n",
    "    \n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_regret = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret/max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette()\n",
    "\n",
    "data = max_regret\n",
    "\n",
    "# makes it easier to identify the policy associated with each line\n",
    "# in the parcoords plot\n",
    "# data['policy'] = data.index.astype(\"float64\")\n",
    "\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['utility', 'inertia', 'reliability', 'max_P']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see striking differences between blue and orange (1 and 3) and green and red (5 and 8). The first two options have low regret on the first three objectives, but higher regret on utility. For the second two options it is reversed\n",
    "\n",
    "Note that we have been looking at the maximum regret. I also saved the distribution of regret over the set of scenarios. So let's visualize this and see what we can learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "policy_regret = defaultdict(dict)\n",
    "for key, value in overall_regret.items():\n",
    "    for policy in value:\n",
    "        policy_regret[policy][key] = value[policy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates a 2 by 2 axes grid, with a shared X and Y axis\n",
    "# accross all plots\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10,10), \n",
    "                         sharey=True, sharex=True)\n",
    "\n",
    "# to ensure easy iteration over the axes grid, we turn it\n",
    "# into a list. Because there are four plots, I hard coded\n",
    "# this. \n",
    "axes = [axes[0,0], axes[0,1],\n",
    "        axes[1,0],]\n",
    "\n",
    "# zip allows us to zip together the list of axes and the list of \n",
    "# key value pairs return by items. If we iterate over this\n",
    "# it returns a tuple of length 2. The first item is the ax\n",
    "# the second items is the key value pair.\n",
    "for ax, (policy, regret) in zip(axes, policy_regret.items()):\n",
    "    data = pd.DataFrame(regret)\n",
    "\n",
    "    # we need to scale the regret to ensure fair visual\n",
    "    # comparison. We can do that by divding by the maximum regret\n",
    "    data = data/max_regret.max(axis=0)\n",
    "    sns.boxplot(data=data, ax=ax)\n",
    "    \n",
    "    # removes top and left hand black outline of axes\n",
    "    sns.despine()\n",
    "    \n",
    "    # ensure we know which policy the figure is for\n",
    "    ax.set_title(str(policy))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
