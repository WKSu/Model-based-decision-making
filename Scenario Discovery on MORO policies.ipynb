{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import every package we need\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario, SequentialEvaluator)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments, optimize, robust_optimize\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.analysis import prim, dimensional_stacking, cart\n",
    "from ema_workbench.util import ema_logging, utilities\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualization_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ee07de09f7af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvisualization_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhistogram_maker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_outcomes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregate_outcomes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter_maker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairplot_maker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxplot_histogram_maker\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'visualization_functions'"
     ]
    }
   ],
   "source": [
    "from visualization_functions import histogram_maker, mean_outcomes, aggregate_outcomes, scatter_maker, pairplot_maker, boxplot_histogram_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from C:\\Users\\newbi\\project-local\\Model-based-decision-making\\Outcomes\\MOROpolicies50Scenarios.csv\n"
     ]
    }
   ],
   "source": [
    "results = utilities.load_results('Outcomes/MOROpolicies50Scenarios.csv')\n",
    "\n",
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness(data):\n",
    "    ''' \n",
    "    Returns a robustness score for a value you want to minimize.\n",
    "    s\n",
    "    We want a function that returns 0 for the outcome to be in the range that we want and higher otherwise.\n",
    "    \n",
    "    Takes in an array and returns a score for each value of the same array.\n",
    "    '''\n",
    "    \n",
    "    # Normalize\n",
    "    mean = np.mean(data)\n",
    "    iqr = np.quantile(data,0.75,axis=0) - np.quantile(data,0.25,axis=0) + mean * 0.005 # Add a small number so the mean is still considered in the score rather than 0\n",
    "    score = mean * iqr\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def aggregate_outcomes(results, outcome):\n",
    "    list_outcomes_columns = []\n",
    "    \n",
    "    for i in results.columns:\n",
    "        if outcome in i:\n",
    "            list_outcomes_columns.append(i)\n",
    "            \n",
    "    results[\"Total \" + str(outcome)] = results[list_outcomes_columns].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.em_framework.optimization import (HyperVolume, \n",
    "                                                     EpsilonProgress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mHyperVolume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminimum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Hypervolume convergence metric class\n",
       "\n",
       "This metric is derived from a hyper-volume measure, which describes the\n",
       "multi-dimensional volume of space contained within the pareto front. When\n",
       "computed with minimum and maximums, it describes the ratio of dominated\n",
       "outcomes to all possible outcomes in the extent of the space.  Getting this\n",
       "number to be high or low is not necessarily important, as not all outcomes\n",
       "within the min-max range will be feasible.  But, having the hypervolume remain\n",
       "fairly stable over multiple generations of the evolutionary algorithm provides\n",
       "an indicator of convergence.\n",
       "\n",
       "Parameters\n",
       "---------\n",
       "minimum : numpy array\n",
       "maximum : numpy array\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\newbi\\anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\optimization.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?HyperVolume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Expected Annual Damage       3.749993e+14\n",
       "Total Dike Investment Costs        1.629135e+16\n",
       "Total Expected Number of Deaths    9.188915e-05\n",
       "Total RfR Total Costs              1.696482e+14\n",
       "Total Expected Evacuation Costs    6.705833e+04\n",
       "Name: 0.75, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = pd.DataFrame(outcomes)\n",
    "experiments = pd.DataFrame(experiments)\n",
    "results = experiments.join(outcomes)\n",
    "results = results.drop(columns=\"model\")\n",
    "\n",
    "# Aggregate\n",
    "aggregate_outcomes(outcomes,\"Expected Annual Damage\")\n",
    "aggregate_outcomes(outcomes,\"Dike Investment Costs\")\n",
    "aggregate_outcomes(outcomes,\"Expected Number of Deaths\")\n",
    "aggregate_outcomes(outcomes,\"RfR Total Costs\")\n",
    "aggregate_outcomes(outcomes,\"Expected Evacuation Costs\")\n",
    "\n",
    "everything = pd.DataFrame(experiments[\"policy\"]).join(outcomes)\n",
    "\n",
    "# Run robustness, find the 75th quantile (or 0,max)\n",
    "robust_values = everything.groupby(by = [\"policy\"]).apply(robustness).iloc[:, -5:]\n",
    "hyp_ranges_min = robust_values.apply(np.min)\n",
    "hyp_ranges_max = robust_values.apply(np.max)\n",
    "robust_values.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Expected Annual Damage       4.611797e+10\n",
       "Total Dike Investment Costs        1.297694e+16\n",
       "Total Expected Number of Deaths    6.234993e-09\n",
       "Total RfR Total Costs              0.000000e+00\n",
       "Total Expected Evacuation Costs    0.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_ranges_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Expected Annual Damage       3.759498e+14\n",
       "Total Dike Investment Costs        1.629135e+16\n",
       "Total Expected Number of Deaths    2.897226e-04\n",
       "Total RfR Total Costs              1.365554e+15\n",
       "Total Expected Evacuation Costs    3.718028e+05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp_ranges_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "results_MORO, convergence = pickle.load(open('Outcomes/MORO_s50_nfe20000.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "from model.dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from model.problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MORO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies = []\n",
    "for row in range(results.shape[0]):\n",
    "    policies.append(\n",
    "        Policy(name = row, **results_MORO.iloc[row,:-5].to_dict())  # Do not include the damage scores\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "#     results = evaluator.perform_experiments(scenarios=50,policies=policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ema_workbench.util.utilities import (save_results, load_results)\n",
    "\n",
    "# save_results(results, \"Outcomes/MOROpolicies50Scenarios.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.util.utilities import (save_results, load_results)\n",
    "\n",
    "results = load_results('Outcomes/MOROpolicies50Scenarios.csv')\n",
    "\n",
    "experiments, outcomes = results\n",
    "outcomes = pd.DataFrame(outcomes)\n",
    "experiments = pd.DataFrame(experiments)\n",
    "results = experiments.join(outcomes)\n",
    "results = results.drop(columns=\"model\")\n",
    "# results = results.apply(pd.to_numeric)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate\n",
    "aggregate_outcomes(outcomes,\"Expected Annual Damage\")\n",
    "aggregate_outcomes(outcomes,\"Dike Investment Costs\")\n",
    "aggregate_outcomes(outcomes,\"Expected Number of Deaths\")\n",
    "aggregate_outcomes(outcomes,\"RfR Total Costs\")\n",
    "aggregate_outcomes(outcomes,\"Expected Evacuation Costs\")\n",
    "\n",
    "everything = pd.DataFrame(experiments[\"policy\"]).join(outcomes)\n",
    "\n",
    "# Run robustness, find the 75th quantile (or 0,max)\n",
    "robust_values = everything.groupby(by = [\"policy\"]).apply(robustness).iloc[:, -5:]\n",
    "hyp_ranges_min = robust_values.apply(np.min)\n",
    "hyp_ranges_max = robust_values.apply(np.max)\n",
    "robust_values.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_maker(results, \"Expected Annual Damage\")\n",
    "histogram_maker(results, \"Expected Number of Deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_outcomes(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caution when looking at the plots, because the legend is not fixed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_maker(results, \"Expected Annual Damage\")\n",
    "scatter_maker(results, \"Expected Number of Deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_maker(results, \"A.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_outcomes(results, \"Expected Number of Deaths\")\n",
    "aggregate_outcomes(results, \"Expected Annual Damage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_histogram_maker(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results.iloc[:, :19] # Only take the uncertentainties \n",
    "\n",
    "y_deaths = results['Total Expected Number of Deaths'].values\n",
    "y_deaths = y_deaths > np.percentile(y_deaths, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_alg = prim.Prim(x, y_deaths, threshold=0.55, peel_alpha=0.005)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.inspect()\n",
    "box1.inspect(style='graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.select(-1)\n",
    "box1.show_pairs_scatter()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further investigation on specific locations\n",
    "\n",
    "Check A.1 as well..\n",
    "\n",
    "Further discovery of location A2 and time step 1 as the scatter plots and histograms showed that the policies are not robust yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_deaths_A1 = results[\"A.1_Expected Number of Deaths 0\"]\n",
    "y_deaths_A1 = y_deaths_A1 > np.percentile(y_deaths_A1, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_alg = prim.Prim(x, y_deaths_A1, threshold=0.40, peel_alpha=0.0001)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.select(-1)\n",
    "box1.show_pairs_scatter()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_alg = cart.CART(x, y_deaths_A1, 0.05)\n",
    "cart_alg.build_tree()\n",
    "\n",
    "print(cart_alg.stats_to_dataframe())\n",
    "print(cart_alg.boxes_to_dataframe())\n",
    "\n",
    "cart_alg.show_tree()\n",
    "fig = plt.gcf()\n",
    "fig.figure(figsize = 12, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_damages_A1 = results[\"A.1_Expected Annual Damage 0\"]\n",
    "y_damages_A1 = y_damages_A1 > np.percentile(y_damages_A1, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_alg = prim.Prim(x, y_deaths_A1, threshold=0.40, peel_alpha=0.1)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.select(-1)\n",
    "box1.show_pairs_scatter()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_alg = cart.CART(x, y_damages_A1, 0.05)\n",
    "cart_alg.build_tree()\n",
    "\n",
    "print(cart_alg.stats_to_dataframe())\n",
    "print(cart_alg.boxes_to_dataframe())\n",
    "\n",
    "cart_alg.show_tree()\n",
    "fig = plt.gcf()\n",
    "fig.figure(figsize = 12, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.2_Expected Annual Damage 0\n",
    "# A.2_Expected Number of Deaths 0\n",
    "\n",
    "y_deaths_A2 = results[\"A.2_Expected Number of Deaths 0\"]\n",
    "y_deaths_A2 = y_deaths_A2 > np.percentile(y_deaths_A2, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_alg = prim.Prim(x, y_deaths_A2, threshold=0.40, peel_alpha=0.0001)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.inspect()\n",
    "box1.inspect(style='graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.select(-1)\n",
    "box1.show_pairs_scatter()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_alg = cart.CART(x, y_deaths_A2, 0.05)\n",
    "cart_alg.build_tree()\n",
    "\n",
    "print(cart_alg.stats_to_dataframe())\n",
    "print(cart_alg.boxes_to_dataframe())\n",
    "\n",
    "cart_alg.show_tree()\n",
    "fig = plt.gcf()\n",
    "fig.figure(figsize = 12, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_damages_A2 = results[\"A.2_Expected Annual Damage 0\"]\n",
    "y_damages_A2 = y_damages_A2 > np.percentile(y_damages_A2, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_alg = prim.Prim(x, y_damages_A2, threshold=0.40, peel_alpha=0.1)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.select(-1)\n",
    "box1.show_pairs_scatter()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA: same coverage\n",
    "\n",
    "# x_numeric = x.select_dtypes(exclude=pd.CategoricalDtype)\n",
    "# x_categorical = x.select_dtypes(include=pd.CategoricalDtype)\n",
    "\n",
    "# rotated_experiments, rotation_matrix = prim.pca_preprocess(x_numeric, y_damages_A2)\n",
    "\n",
    "# rotated_x = pd.concat([rotated_experiments, x_categorical], axis=1)\n",
    "\n",
    "# prim_obj = prim.Prim(rotated_x, y_damages_A2, threshold=0.1, peel_alpha=0.1)\n",
    "# box1 = prim_obj.find_box()\n",
    "\n",
    "# box1.show_tradeoff()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_alg = cart.CART(x, y_damages_A2, 0.05)\n",
    "cart_alg.build_tree()\n",
    "\n",
    "print(cart_alg.stats_to_dataframe())\n",
    "print(cart_alg.boxes_to_dataframe())\n",
    "\n",
    "cart_alg.show_tree()\n",
    "fig = plt.gcf()\n",
    "fig.figure(figsize = 12, 12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
